{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from random import randrange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 12) # set default size of plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения мы будем использовать датасет CIFAR-10, состоящий из 60000 цветных изображений размера 32x32, разбитых на 10 классов, по 6000 изображений на класс. Обучающая выборка состоит из 50000 изображений, а тестовая -- из 10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 10\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(x_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: вычитаем среднее\n",
    "# 1: Находим среднее изображение\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # визуализируем полученное среднее\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2: вычитаем среднее из изображений обучающей и тестовых выборок\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуем решить задачу при помощи простой нейронной сети. Сначала объявим функцию, описывающую граф модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_model():\n",
    "    # placeholder'ы это точки входа, можно восприпимать их, как аргументы функции, описываемой графом\n",
    "    x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "    y = tf.placeholder(tf.int64, [None])\n",
    "    \n",
    "    #variable scope задаёт префикс для всех элементов внутри него\n",
    "    #Это позволяет огранизовавывать структуру графа и вашего кода\n",
    "    with tf.variable_scope(\"convolution_layer_1\"):\n",
    "        #создаём веса (W -- ядра свёрток, b -- сдвиг)\n",
    "        Wconv1 = tf.get_variable(\"Wconv1\", shape=[7, 7, 3, 32])\n",
    "        bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "        \n",
    "        a1 = tf.nn.conv2d(x, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "        h1 = tf.nn.relu(a1)\n",
    "    \n",
    "    #добавляем полносвязный слой\n",
    "    with tf.variable_scope(\"dense_layer_1\"):\n",
    "        W1 = tf.get_variable(\"W1\", shape=[5408, 10])\n",
    "        b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "        \n",
    "        h1_flat = tf.reshape(h1,[-1,5408])\n",
    "        y_out = tf.matmul(h1_flat,W1) + b1\n",
    "\n",
    "        \n",
    "    # y_out -- это вектор оценок, которые генерирует модель. Теперь определим функцию потерь\n",
    "    total_loss = tf.losses.hinge_loss(tf.one_hot(y,10),logits=y_out)\n",
    "    mean_loss = tf.reduce_mean(total_loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_out,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #Возвращаем те узлы графа, которые нам понадобятся в дальнейшем.\n",
    "    #(x,y) это входы графа, а (y_out, mean_loss) выходы, которые представляют для нас интерес\n",
    "    return (x,y), (y_out, mean_loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написанная выше функция не осуществляет никаких вычислений, единственное её предназначение -- описание графа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Перед вызовом функции очистим память от графов других моделей (актуально если вы вызываете эту ячейку повторно)\n",
    "tf.reset_default_graph()\n",
    "(x,y), (y_out, mean_loss, accuracy) = build_simple_model()\n",
    "\n",
    "#Теперь зададим алгоритм оптимизации\n",
    "optimizer = tf.train.AdamOptimizer(5e-5) \n",
    "#train_step -- специальный служебный узел в графе, отвечающий за обратный проход\n",
    "train_step = optimizer.minimize(mean_loss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуйста, ознакомьтесь с другими возможностями, которые предоставляет tf для описания модели. \n",
    "\n",
    "* Layers, Activations, Loss functions : https://www.tensorflow.org/api_guides/python/nn\n",
    "* Optimizers: https://www.tensorflow.org/api_guides/python/train#Optimizers\n",
    "* BatchNorm: https://www.tensorflow.org/api_docs/python/tf/layers/BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем двигаться дальше и протестировать получившуюся модель. Для этого реализуем тренировочный цикл\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_loop(session, model_inputs, model_outputs, train_step, epochs=10, batch_size=64):\n",
    "    #создаём индекс по всем объектам\n",
    "    index = np.arange(len(x_train))\n",
    "    \n",
    "    #перемешиваем его\n",
    "    np.random.shuffle(index)\n",
    "    \n",
    "    #разбиваем на батчи\n",
    "    num_batches = int(len(index) / batch_size)\n",
    "    batch_indexes = np.array_split(index, num_batches)\n",
    "    \n",
    "    #аналогично для теста\n",
    "    index_test = np.arange(len(x_test))\n",
    "    np.random.shuffle(index_test)\n",
    "    num_batches_test = int(len(index_test) / batch_size)\n",
    "    batch_indexes_test = np.array_split(index_test, num_batches_test)\n",
    "    \n",
    "    #аналогично для validation\n",
    "    index_val = np.arange(len(x_val))\n",
    "    np.random.shuffle(index_val)\n",
    "    num_batches_val = int(len(index_val) / batch_size)\n",
    "    batch_indexes_val = np.array_split(index_val, num_batches_val)\n",
    "    \n",
    "    \n",
    "    x,y = model_inputs\n",
    "    y_out, mean_loss, accuracy = model_outputs\n",
    "    \n",
    "    def train(x_values, y_values, batch_indexes):\n",
    "        train_loses = []\n",
    "        for i, batch_index in enumerate(batch_indexes):\n",
    "\n",
    "            #Создаём словарь, осуществляющий сопоставление входов графа (plaseholders) и значений\n",
    "            feed_dict = {x: x_values[batch_index],\n",
    "                         y: y_values[batch_index]}\n",
    "\n",
    "            #Здесь происходит непоследственный вызов модели\n",
    "            #Обратите внимание, что мы передаём train_step\n",
    "            scores, loss, acc, _ = session.run([y_out, mean_loss, accuracy, train_step],feed_dict=feed_dict)\n",
    "\n",
    "            train_loses.append(loss)\n",
    "            print(f'iteration {i}, train loss: {loss:.3}, accuracy: {acc:.3}', end='\\r')\n",
    "        return train_loses\n",
    "        \n",
    "    def evaluate(x_values, y_values, batch_indexes):\n",
    "        test_loses = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for batch_index in batch_indexes:\n",
    "\n",
    "            #Создаём словарь, осуществляющий сопоставление входов графа (plaseholders) и значений\n",
    "            feed_dict = {x: x_values[batch_index],\n",
    "                         y: y_values[batch_index]}\n",
    "\n",
    "            #Здесь происходит непоследственный вызов модели\n",
    "            loss, acc = session.run([mean_loss, accuracy],feed_dict=feed_dict)\n",
    "\n",
    "            test_loses.append(loss)\n",
    "            test_accuracy.append(acc)\n",
    "\n",
    "        return test_loses, test_accuracy\n",
    "    \n",
    "    # цикл по эпохам\n",
    "    for e in range(epochs):\n",
    "        print(f'Epoch {e}:')\n",
    "        train_loses = train(x_train, y_train, batch_indexes)\n",
    "        val_loses, val_accuracy = evaluate(x_val, y_val, batch_indexes_val)\n",
    "        print(f'train loss: {np.mean(train_loses):.3}, val loss: {np.mean(val_loses):.3}, accuracy: {np.mean(val_accuracy):.3}')\n",
    "      \n",
    "    print('================================================')\n",
    "    print('Test set results:')\n",
    "    test_loses, test_accuracy = evaluate(x_test, y_test, batch_indexes_test)\n",
    "    print(f'test loss: {np.mean(test_loses):.3}, accuracy: {np.mean(test_accuracy):.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём сессию. Сессия -- это среда, в которой выполняются вычисления\n",
    "with tf.Session() as sess:\n",
    "    #мы можем явно указать устройство\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        #инициализируем веса, в этот момент происходит выделение памяти\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #запускаем тренировку\n",
    "        training_loop(sess, model_inputs=(x,y), \n",
    "                      model_outputs=(y_out, mean_loss, accuracy), \n",
    "                      train_step=train_step, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, даже самая простая модель показывает очень неплохие результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Задача 1:** Модифицируйте предыдущий код так, чтобы данные о тренировке (train\\val loss) выводились в tensorboard. Изучите визуализацию графа модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача 2 (основная)** Реализуйте сеть, подобную [VGG-16](https://arxiv.org/pdf/1409.1556.pdf) (или любую другую), для решения задачи. При реализации вам не разрешается пользоваться модулем **tf.layers** за исключением **tf.layers.batch_normalization** и **tf.layers.dropout**. Обратите внимание, что VGG-16 заточена под изображения большего разрешения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем, после того, как сеть будет реализована постарайтесь получить масимально возможную точность, используя методы, описанные в лекциях (batch normalization, расписание learning rate, поменяйте функции активации, аугментация данных и т.д.). Результаты каждого слушателя затем будут занесены в таблицу и вывешены в репозитории курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принимаются работы с точностью **не менее 84%**. \n",
    "\n",
    "Полезные ссылки:\n",
    "  - [ResNet](https://arxiv.org/abs/1512.03385).\n",
    "  - [DenseNet](https://arxiv.org/abs/1608.06993).\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите ваш код под текстом задания"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
